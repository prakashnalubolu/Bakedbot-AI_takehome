{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# !pip install gradio pandas"
      ],
      "metadata": {
        "id": "m2BNWB5XWlOo"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WqCJCeXfdA3U"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "BakedBot AI: Cannabis Strain Recommendation(RAG using BM25)\n",
        "- Indexes text fields (dominant_terpenes, flavor_notes, effects) with BM25\n",
        "- Retrieves top 3 strains for a free-text query\n",
        "- Ranks with BM25 and a gentle review-based boost\n",
        "- Generates a short recommendation blurb per result\n",
        "- UI to see the results of recommendation system\n",
        "\"\"\"\n",
        "import re\n",
        "import math\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "import gradio as gr\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CSV_PATH = \"sample_cannabis_strains.csv\"  #File path\n",
        "# Build corpus from text fields\n",
        "TEXT_FIELDS = [\"dominant_terpenes\", \"flavor_notes\", \"effects\"] #provided in CSV\n",
        "\n",
        "# Small synonym maps to help query intent\n",
        "TERP_SYNONYMS = { \"myrcene\": [\"myrcene\"],\n",
        "                  \"limonene\": [\"limonene\", \"citrus\"],\n",
        "                  \"pinene\": [\"pinene\", \"pine\"],\n",
        "                  \"caryophyllene\": [\"caryophyllene\", \"pepper\", \"spicy\"],\n",
        "                  \"humulene\": [\"humulene\", \"hoppy\"],\n",
        "                  \"bisabolol\": [\"bisabolol\"]\n",
        "                }\n",
        "\n",
        "EFFECT_SYNONYMS = { \"sleep\": [\"sleep\", \"sleepy\", \"insomnia\"],\n",
        "                    \"anxiety\": [\"anxiety\", \"calm\", \"relax\", \"relaxed\", \"stress\"],\n",
        "                    \"focus\": [\"focus\", \"focused\"],\n",
        "                    \"energy\": [\"energy\", \"energetic\", \"uplifted\"],\n",
        "                    \"happy\": [\"happy\", \"euphoric\"],\n",
        "                    \"creative\": [\"creative\"],\n",
        "                    \"pain\": [\"pain\", \"analgesic\"]\n",
        "                  }"
      ],
      "metadata": {
        "id": "3RugDNeaWhi3"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core retrieval: BM25\n",
        "def bm25(corpus, query, k1=1.5, b=0.75):\n",
        "    \"\"\"\n",
        "    Compute BM25 scores for a tokenized query against a tokenized corpus.\n",
        "    Arguments:\n",
        "        corpus: list[list[str]] where each inner list is a tokenized document.\n",
        "        query:  list[str] tokenized query terms.\n",
        "        k1, b:  Standard BM25 hyperparameters.\n",
        "    Returns:\n",
        "        list[float]: BM25 score per document in same order as corpus.\n",
        "    \"\"\"\n",
        "    N = len(corpus)\n",
        "    avgdl = sum(len(doc) for doc in corpus) / N\n",
        "    # Document frequency for each term\n",
        "    df = {}\n",
        "    for doc in corpus:\n",
        "        for word in set(doc):\n",
        "            df[word] = df.get(word, 0) + 1\n",
        "    # Inverse document frequency\n",
        "    idf = {word: math.log((N - df[word] + 0.5) / (df[word] + 0.5) + 1)\n",
        "           for word in df}\n",
        "    scores = []\n",
        "    for doc in corpus:\n",
        "        score = 0.0\n",
        "        freq = Counter(doc)\n",
        "        for term in query:\n",
        "            if term in freq:\n",
        "                numerator = freq[term] * (k1 + 1)\n",
        "                denominator = freq[term] + k1 * (1 - b + b * len(doc) / avgdl)\n",
        "                score += idf.get(term, 0) * (numerator / denominator)\n",
        "        scores.append(score)\n",
        "    return scores"
      ],
      "metadata": {
        "id": "DdH0RQN3XQmF"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization & expansion\n",
        "\n",
        "token_re = re.compile(r\"[a-zA-Z0-9]+\")\n",
        "\n",
        "def tokenize(text: str):\n",
        "    \"\"\"\n",
        "    Lowercase alphanumeric tokenizer.\n",
        "    Example: \"Berry, Earthy\" -> [\"berry\",\"earthy\"]\n",
        "    \"\"\"\n",
        "    return [t.lower() for t in token_re.findall(text or \"\")]\n",
        "\n",
        "def expand_terms(tokens):\n",
        "    \"\"\"\n",
        "    Light synonym expansion: if a token matches a known key or synonym\n",
        "    (Example: \"sleep\" or \"insomnia\"), include the base term too.\n",
        "    This gently improves recall without heavy \"NLP\" dependencies.\n",
        "    \"\"\"\n",
        "    expanded = set(tokens)\n",
        "    maps = {}\n",
        "    maps.update(TERP_SYNONYMS)\n",
        "    maps.update(EFFECT_SYNONYMS)\n",
        "    for base, alts in maps.items():\n",
        "        if base in tokens or any(t in tokens for t in alts):\n",
        "            expanded.update(alts + [base])\n",
        "    return list(expanded)"
      ],
      "metadata": {
        "id": "Zg2bhaiFXowM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data loading & corpus build\n",
        "def load_data(csv_path: str) -> pd.DataFrame:\n",
        "    \"\"\"\n",
        "    Load strains CSV and normalize key numeric columns.\n",
        "    Required fields: strain_name, type, thc_pct, cbd_pct, dominant_terpenes,\n",
        "                     flavor_notes, effects, avg_review_score, review_count\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(csv_path)\n",
        "    for col in [\"thc_pct\", \"cbd_pct\", \"avg_review_score\", \"review_count\"]:\n",
        "        if col in df.columns:\n",
        "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
        "    return df\n",
        "\n",
        "def row_to_doc(row: pd.Series) -> str:\n",
        "    \"\"\"\n",
        "    Concatenate the text fields we want to index into a single\n",
        "    space-separated string (later tokenized).\n",
        "    \"\"\"\n",
        "    parts = [str(row.get(f, \"\")) for f in TEXT_FIELDS]\n",
        "    return \" \".join(parts)"
      ],
      "metadata": {
        "id": "nRHdOaAiYepL"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Scoring and Ranking\n",
        "\n",
        "def review_boost(row: pd.Series, alpha: float = 0.25, beta: float = 0.25) -> float:\n",
        "    \"\"\"\n",
        "    Compute a multiplicative boost based on review quality & volume.\n",
        "    - avg_review_score (1..5) -> score_norm 1→-1, 3→0, 5→1\n",
        "    - review_count -> log-scaled vs dataset max to avoid outliers\n",
        "    Boost = (1 + alpha * score_norm) * (1 + beta * count_norm)\n",
        "    \"\"\"\n",
        "    score = float(row.get(\"avg_review_score\", 0) or 0.0)\n",
        "    count = float(row.get(\"review_count\", 0) or 0.0)\n",
        "\n",
        "    # Map 3.0 (neutral) -> 0.0, 5.0 -> 1.0\n",
        "    score_norm = max(0.0, (score - 3.0) / 2.0)\n",
        "\n",
        "    # Log-scale review counts to 0..1\n",
        "    # (max_count must be injected from the global dataframe, set later)\n",
        "    global _MAX_REVIEW_COUNT\n",
        "    max_count = max(1.0, float(_MAX_REVIEW_COUNT))\n",
        "    count_norm = math.log1p(count) / math.log1p(max_count)\n",
        "\n",
        "    return (1 + alpha * score_norm) * (1 + beta * count_norm)\n",
        "\n",
        "def score_query(query_text: str, df: pd.DataFrame, corpus: list[list[str]]) -> list[dict]:\n",
        "    \"\"\"\n",
        "    Score a free-text query against the corpus and return top-3 results.\n",
        "    Returns a list of dicts with metadata, BM25, boost, final_score, and recommendation.\n",
        "    \"\"\"\n",
        "    # Tokenize & lightly expand query\n",
        "    q_tokens = expand_terms(tokenize(query_text))\n",
        "\n",
        "    # BM25 over our prebuilt tokenized corpus\n",
        "    base_scores = bm25(corpus, q_tokens)\n",
        "\n",
        "    # Compose results, apply review-based boost, then sort\n",
        "    results = []\n",
        "    for i, s in enumerate(base_scores):\n",
        "        row = df.iloc[i]\n",
        "        b = review_boost(row)\n",
        "        final = s * b\n",
        "        results.append({\n",
        "            \"rank\": None,\n",
        "            \"strain_name\": row.get(\"strain_name\"),\n",
        "            \"type\": row.get(\"type\"),\n",
        "            \"thc_pct\": row.get(\"thc_pct\"),\n",
        "            \"cbd_pct\": row.get(\"cbd_pct\"),\n",
        "            \"bm25\": round(float(s), 4),\n",
        "            \"boost\": round(float(b), 4),\n",
        "            \"final_score\": round(float(final), 4),\n",
        "            \"dominant_terpenes\": row.get(\"dominant_terpenes\"),\n",
        "            \"flavor_notes\": row.get(\"flavor_notes\"),\n",
        "            \"effects\": row.get(\"effects\"),\n",
        "            \"avg_review_score\": row.get(\"avg_review_score\"),\n",
        "            \"review_count\": row.get(\"review_count\"),\n",
        "        })\n",
        "\n",
        "    results.sort(key=lambda x: x[\"final_score\"], reverse=True)\n",
        "\n",
        "    # Fill in rank + generate a short blurb\n",
        "    top_k = results[:3]\n",
        "    for r_idx, r in enumerate(top_k, start=1):\n",
        "        r[\"rank\"] = r_idx\n",
        "        r[\"recommendation\"] = generate_recommendation(r, query_text)\n",
        "    return top_k"
      ],
      "metadata": {
        "id": "7lghmpIZYhBZ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate Recommendation\n",
        "def generate_recommendation(item: dict, query_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Produce a short, readable explanation tying the result to the query:\n",
        "      - references terpenes/effects and THC/CBD\n",
        "      - calls out common intents (sleep, anxiety, focus, energy, creativity)\n",
        "      - mentions review summary for credibility\n",
        "    \"\"\"\n",
        "    hints = []\n",
        "    q = query_text.lower()\n",
        "    if \"sleep\" in q or \"insomnia\" in q:\n",
        "        hints.append(\"reports sleepy/relaxing effects\")\n",
        "    if any(w in q for w in [\"anxiety\", \"stress\", \"calm\"]):\n",
        "        hints.append(\"often chosen to ease stress or anxiety\")\n",
        "    if \"focus\" in q:\n",
        "        hints.append(\"reviewers mention focus/clarity\")\n",
        "    if any(w in q for w in [\"energy\", \"energetic\"]):\n",
        "        hints.append(\"uplifting/energizing profile\")\n",
        "    if \"creative\" in q:\n",
        "        hints.append(\"can support creativity\")\n",
        "    if \"myrcene\" in q and \"myrcene\" in (item.get(\"dominant_terpenes\",\"\").lower()):\n",
        "        hints.append(\"dominant in myrcene as requested\")\n",
        "    if \"limonene\" in q and \"limonene\" in (item.get(\"dominant_terpenes\",\"\").lower()):\n",
        "        hints.append(\"limonene-forward profile matches query\")\n",
        "\n",
        "    terp = item.get(\"dominant_terpenes\") or \"—\"\n",
        "    eff = item.get(\"effects\") or \"—\"\n",
        "    thc = item.get(\"thc_pct\")\n",
        "    cbd = item.get(\"cbd_pct\")\n",
        "    preface = f\"{item['strain_name']} ({item['type']}) with {terp}; effects include {eff}. THC {thc}%, CBD {cbd}%.\"\n",
        "    tail = (\" \" + \" \".join(hints)) if hints else \"\"\n",
        "    meta = f\" Avg review {item['avg_review_score']}/5 from {item['review_count']} reviews.\"\n",
        "    return preface + tail + meta"
      ],
      "metadata": {
        "id": "vHLkDpmChOQV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio UI\n",
        "def build_ui(df: pd.DataFrame, corpus: list[list[str]]):\n",
        "    \"\"\"\n",
        "    Build a tiny Gradio UI: text input -> top 3 results with scores & blurbs.\n",
        "    \"\"\"\n",
        "    example_queries = [\n",
        "        \"High in myrcene, good for sleep and anxiety\",\n",
        "        \"Limonene citrus notes, uplifting and creative\",\n",
        "        \"Low THC, higher CBD for focus\",\n",
        "    ]\n",
        "\n",
        "    def _search(query: str) -> str:\n",
        "        top = score_query(query, df, corpus)\n",
        "        lines = []\n",
        "        for r in top:\n",
        "            lines.append(\n",
        "                f\"#{r['rank']} — {r['strain_name']} | Final: {r['final_score']} (BM25 {r['bm25']} × Boost {r['boost']})\\n\"\n",
        "                f\"Terpenes: {r['dominant_terpenes']} | Effects: {r['effects']} | THC {r['thc_pct']}% | CBD {r['cbd_pct']}%\\n\"\n",
        "                f\"Recommendation: {r['recommendation']}\\n\"\n",
        "            )\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    with gr.Blocks() as demo:\n",
        "        gr.Markdown(\"# BakedBot AI - Cannabis Strain RAG (BM25)\")\n",
        "        gr.Markdown(\"Type what you're looking for (terpenes/effects). Returns top 3 with scores.\")\n",
        "        inp = gr.Textbox(label=\"Your query\", value=example_queries[0])\n",
        "        btn = gr.Button(\"Search\")\n",
        "        out = gr.Textbox(label=\"Results\", lines=15)\n",
        "        btn.click(_search, inputs=inp, outputs=out)\n",
        "        gr.Examples(example_queries, inputs=inp)\n",
        "    return demo\n",
        "\n"
      ],
      "metadata": {
        "id": "SwallHI2hdLZ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "df = load_data(CSV_PATH)\n",
        "\n",
        "# Precompute max review count for boosting\n",
        "_MAX_REVIEW_COUNT = float(df[\"review_count\"].max()) if \"review_count\" in df.columns else 1.0\n",
        "\n",
        "# Build tokenized corpus\n",
        "docs_raw = [row_to_doc(row) for _, row in df.iterrows()]\n",
        "corpus = [tokenize(text) for text in docs_raw]\n",
        "\n",
        "# Launch UI\n",
        "app = build_ui(df, corpus)\n",
        "app.launch(debug=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "id": "AjbomqdGi7vV",
        "outputId": "f1bd7338-7051-4cb2-d075-5b4e0b2f22c0"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://387ce35a0635c7de3b.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://387ce35a0635c7de3b.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}